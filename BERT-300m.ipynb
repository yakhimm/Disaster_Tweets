{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2891,"status":"ok","timestamp":1686455502834,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"4uIKuM5JaMKa","outputId":"2aa890cd-15cf-44af-b097-93cab73783f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6708,"status":"ok","timestamp":1686455509540,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"buN1wy9AaJgx"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout\n","import tensorflow_hub as hub"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686455509541,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"oshyMacAaJgx"},"outputs":[],"source":["random_state_split = 42\n","Dropout_num = 0\n","learning_rate = 5.95e-6\n","valid = 0.15\n","epochs_num = 3\n","batch_size_num = 16\n","target_corrected = False\n","target_big_corrected = False"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686455509542,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"UCQ-VO0UaJgy"},"outputs":[],"source":["url = '/content/drive/My Drive/SyncPC/Data Analytic/DisasterTweet'\n","\n","train_df = pd.read_csv(f'{url}/train.csv')\n","test_df = pd.read_csv(f'{url}/test.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686455509542,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"jA5ouK9saJgy"},"outputs":[],"source":["def bert_encode(texts, tokenizer, max_len=512):\n","    all_tokens = []\n","    all_masks = []\n","    all_segments = []\n","    \n","    for text in texts:\n","        text = tokenizer.tokenize(text)\n","            \n","        text = text[:max_len-2]\n","        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n","        pad_len = max_len - len(input_sequence)\n","        \n","        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n","        tokens += [0] * pad_len\n","        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n","        segment_ids = [0] * max_len\n","        \n","        all_tokens.append(tokens)\n","        all_masks.append(pad_masks)\n","        all_segments.append(segment_ids)\n","    \n","    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1686455509543,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"kWTLYGvsaJgz"},"outputs":[],"source":["def build_model(bert_layer, max_len=512):\n","    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n","\n","    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n","    clf_output = sequence_output[:, 0, :]\n","    \n","    if Dropout_num == 0:\n","        out = Dense(1, activation='sigmoid')(clf_output)\n","    else:\n","        x = Dropout(Dropout_num)(clf_output)\n","        out = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n","    model.compile(Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":24645,"status":"ok","timestamp":1686455534172,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"tzehFJY4aJgz"},"outputs":[],"source":["module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n","bert_layer = hub.KerasLayer(module_url, trainable=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686455534173,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"WBsLC2qFbNSI"},"outputs":[],"source":["# !pip install bert-tensorflow"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1686455534173,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"QMrmDdgEaJg0"},"outputs":[],"source":["# Load tokenizer from the bert layer\n","from bert import tokenization\n","\n","vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n","do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n","tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2265,"status":"ok","timestamp":1686455536427,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"CU-8dhMdaJg0"},"outputs":[],"source":["import sys\n","from absl import flags\n","sys.argv=['preserve_unused_tokens=False']\n","flags.FLAGS(sys.argv)\n","\n","# Encode the text into tokens, masks, and segment flags\n","X_train = bert_encode(train_df.text.values, tokenizer, max_len=160)\n","X_test = bert_encode(test_df.text.values, tokenizer, max_len=160)\n","y_train = train_df.target.values"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1166,"status":"ok","timestamp":1686455537591,"user":{"displayName":"Phạm Gia Khiêm","userId":"15219764217297816792"},"user_tz":-420},"id":"lzsWajUHaJg1","outputId":"7460e758-6abc-41c4-a960-d76429948ccc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 160)]        0           []                               \n","                                                                                                  \n"," input_mask (InputLayer)        [(None, 160)]        0           []                               \n","                                                                                                  \n"," segment_ids (InputLayer)       [(None, 160)]        0           []                               \n","                                                                                                  \n"," keras_layer (KerasLayer)       [(None, 1024),       335141889   ['input_word_ids[0][0]',         \n","                                 (None, 160, 1024)]               'input_mask[0][0]',             \n","                                                                  'segment_ids[0][0]']            \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 1024)        0           ['keras_layer[0][1]']            \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," dense (Dense)                  (None, 1)            1025        ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n","==================================================================================================\n","Total params: 335,142,914\n","Trainable params: 335,142,913\n","Non-trainable params: 1\n","__________________________________________________________________________________________________\n"]}],"source":["# Build BERT model with my tuning\n","model = build_model(bert_layer, max_len=160)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bTbrQsPaJg1","outputId":"696e04ff-50ef-49e9-e7a2-d775e7aaf2f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/4\n","373/373 [==============================] - 832s 2s/step - loss: 0.4512 - accuracy: 0.8014 - val_loss: 0.4009 - val_accuracy: 0.8281\n","Epoch 2/4\n","373/373 [==============================] - 631s 2s/step - loss: 0.3582 - accuracy: 0.8526 - val_loss: 0.4230 - val_accuracy: 0.8167\n","Epoch 3/4\n"," 13/373 [>.............................] - ETA: 9:17 - loss: 0.2126 - accuracy: 0.9135"]}],"source":["checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n","\n","train_history = model.fit(\n","    X_train, y_train,\n","    validation_split = valid,\n","    epochs = epochs_num, # recomended 3-5 epochs\n","    callbacks=[checkpoint],\n","    batch_size = batch_size_num\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6yWM_l0hcLIe"},"outputs":[],"source":["# Prediction by BERT model with my tuning\n","model.load_weights('model.h5')\n","y_pred = model.predict(X_test)\n","y_pred = y_pred.round().astype('int')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wzt_hSZjlPsb"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","\n","ans = pd.read_csv(f'{url}/ans.csv')['target'].values\n","accuracy_score(y_pred= y_pred, y_true= ans)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJyJwT6CU-dc"},"outputs":[],"source":["submission = pd.DataFrame()\n","submission['id'] = test_df['id']\n","submission['target'] = y_pred.reshape(-1)\n","submission.to_csv(f'{url}/submission_BERT.csv', index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
